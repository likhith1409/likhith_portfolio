[{"content":"\u003ch2 id=\"plastic-classification-using-transfer-learning\"\u003ePlastic Classification using Transfer Learning\u003c/h2\u003e\n\u003cp\u003eIn this blog post, we will walk through the process of building a deep learning model to classify different types of plastic using \u003cstrong\u003eTransfer Learning\u003c/strong\u003e with \u003cstrong\u003eTensorFlow\u003c/strong\u003e. We will use a pre-trained \u003cstrong\u003eMobileNetV2\u003c/strong\u003e model and fine-tune it for our specific task. The goal is to classify plastic images into one of seven categories: \u003cstrong\u003eHDPE, LDPE, Other, PET, PP, PS, PVC\u003c/strong\u003e.\u003c/p\u003e\n\u003ch2 id=\"table-of-contents\"\u003eTable of Contents\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"#introduction\"\u003eIntroduction\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#dataset-preparation\"\u003eDataset Preparation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#model-building\"\u003eModel Building\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#training-the-model\"\u003eTraining the Model\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#model-evaluation\"\u003eModel Evaluation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#visualizing-results\"\u003eVisualizing Results\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#conclusion\"\u003eConclusion\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003ePlastic classification is an important task in recycling and waste management. Automating this process using deep learning can significantly improve efficiency. In this project, we leverage \u003cstrong\u003eTransfer Learning\u003c/strong\u003e to build a model that can classify different types of plastic based on images.\u003c/p\u003e\n\u003ch3 id=\"why-transfer-learning\"\u003eWhy Transfer Learning?\u003c/h3\u003e\n\u003cp\u003eTransfer Learning allows us to use a pre-trained model (trained on a large dataset like ImageNet) and fine-tune it for our specific task. This approach is beneficial when we have a limited dataset, as it helps in achieving good performance without requiring a massive amount of data.\u003c/p\u003e\n\u003ch2 id=\"dataset-preparation\"\u003eDataset Preparation\u003c/h2\u003e\n\u003ch3 id=\"dataset-overview\"\u003eDataset Overview\u003c/h3\u003e\n\u003cp\u003eThe dataset consists of images of plastic items from seven different classes:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eHDPE\u003c/strong\u003e (High-Density Polyethylene)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLDPE\u003c/strong\u003e (Low-Density Polyethylene)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOther\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePET\u003c/strong\u003e (Polyethylene Terephthalate)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePP\u003c/strong\u003e (Polypropylene)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePS\u003c/strong\u003e (Polystyrene)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePVC\u003c/strong\u003e (Polyvinyl Chloride)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe dataset is split into three parts:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eTraining set\u003c/strong\u003e: 1,270 images\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eValidation set\u003c/strong\u003e: 354 images\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTest set\u003c/strong\u003e: 187 images\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"data-augmentation\"\u003eData Augmentation\u003c/h3\u003e\n\u003cp\u003eTo improve the model\u0026rsquo;s ability to generalize, we apply \u003cstrong\u003edata augmentation\u003c/strong\u003e to the training set. This includes:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRandom rotation\u003c/li\u003e\n\u003cli\u003eWidth/height shifts\u003c/li\u003e\n\u003cli\u003eShearing\u003c/li\u003e\n\u003cli\u003eZooming\u003c/li\u003e\n\u003cli\u003eHorizontal flipping\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003etrain_datagen \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeras\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epreprocessing\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eimage\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eImageDataGenerator(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    rescale\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1.\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e/\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e255\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    rotation_range\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e20\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    width_shift_range\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e0.2\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    height_shift_range\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e0.2\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    shear_range\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e0.2\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    zoom_range\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e0.2\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    horizontal_flip\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    fill_mode\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;nearest\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"data-generators\"\u003eData Generators\u003c/h3\u003e\n\u003cp\u003eWe use TensorFlow\u0026rsquo;s \u003ccode\u003eImageDataGenerator\u003c/code\u003e to create data generators for training, validation, and testing.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003etrain_generator \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e train_datagen\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eflow_from_directory(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    train_dir,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    target_size\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003eIMG_SIZE,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    batch_size\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003eBATCH_SIZE,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    class_mode\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;categorical\u0026#39;\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    shuffle\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eval_generator \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e test_val_datagen\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eflow_from_directory(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    val_dir,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    target_size\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003eIMG_SIZE,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    batch_size\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003eBATCH_SIZE,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    class_mode\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;categorical\u0026#39;\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    shuffle\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eFalse\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003etest_generator \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e test_val_datagen\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eflow_from_directory(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    test_dir,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    target_size\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003eIMG_SIZE,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    batch_size\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003eBATCH_SIZE,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    class_mode\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;categorical\u0026#39;\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    shuffle\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eFalse\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"model-building\"\u003eModel Building\u003c/h3\u003e\n\u003ch2 id=\"transfer-learning-with-mobilenetv2\"\u003eTransfer Learning with MobileNetV2\u003c/h2\u003e\n\u003cp\u003eWe use \u003cstrong\u003eMobileNetV2\u003c/strong\u003e as the base model for transfer learning. MobileNetV2 is a lightweight and efficient model that is well-suited for mobile and embedded vision applications.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ebuild_model\u003c/span\u003e():\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    base_model \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e applications\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eMobileNetV2(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        input_shape\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003eINPUT_SHAPE,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        include_top\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eFalse\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        weights\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;imagenet\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    )\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    base_model\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etrainable \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eFalse\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    inputs \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeras\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eInput(shape\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003eINPUT_SHAPE)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    x \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e base_model(inputs, training\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eFalse\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    x \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e layers\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eGlobalAveragePooling2D()(x)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    x \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e layers\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eDropout(\u003cspan style=\"color:#ae81ff\"\u003e0.2\u003c/span\u003e)(x)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    x \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e layers\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eDense(\u003cspan style=\"color:#ae81ff\"\u003e128\u003c/span\u003e, activation\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;relu\u0026#39;\u003c/span\u003e)(x)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    outputs \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e layers\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eDense(NUM_CLASSES, activation\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;softmax\u0026#39;\u003c/span\u003e)(x)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    model \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e models\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eModel(inputs, outputs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e model\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"model-summary\"\u003eModel Summary\u003c/h3\u003e\n\u003cp\u003eThe model consists of:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eBase Model\u003c/strong\u003e: MobileNetV2 (pre-trained on ImageNet)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGlobalAveragePooling2D\u003c/strong\u003e: To reduce dimensionality.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDropout (0.2)\u003c/strong\u003e: To prevent overfitting.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDense (128 units)\u003c/strong\u003e: Fully connected layer with ReLU activation.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDense (7 units)\u003c/strong\u003e: Output layer with softmax activation for multi-class classification.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003emodel\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003esummary()\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"training-the-model\"\u003eTraining the Model\u003c/h3\u003e\n\u003ch2 id=\"compilation\"\u003eCompilation\u003c/h2\u003e\n\u003cp\u003eWe compile the model using the \u003cstrong\u003eAdam optimizer\u003c/strong\u003e with an exponential learning rate decay.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einitial_learning_rate \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1e-4\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003elr_schedule \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeras\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eoptimizers\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eschedules\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eExponentialDecay(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    initial_learning_rate,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    decay_steps\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e100\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    decay_rate\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e0.96\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    staircase\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003emodel\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ecompile(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    optimizer\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003etf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeras\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eoptimizers\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eAdam(learning_rate\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003elr_schedule),\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    loss\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;categorical_crossentropy\u0026#39;\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    metrics\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;accuracy\u0026#39;\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"callbacks\"\u003eCallbacks\u003c/h2\u003e\n\u003cp\u003eWe use \u003cstrong\u003eEarly Stopping\u003c/strong\u003e and \u003cstrong\u003eModel Checkpoint\u003c/strong\u003e callbacks to prevent overfitting and save the best model.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eearly_stopping \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e callbacks\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eEarlyStopping(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    monitor\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;val_loss\u0026#39;\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    patience\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e10\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    restore_best_weights\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003emodel_checkpoint \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e callbacks\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eModelCheckpoint(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;best_model.h5\u0026#39;\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    save_best_only\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    monitor\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;val_accuracy\u0026#39;\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    mode\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;max\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"training\"\u003eTraining\u003c/h2\u003e\n\u003cp\u003eThe model is trained for 50 epochs.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ehistory \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e model\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efit(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    train_generator,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    epochs\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003eEPOCHS,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    validation_data\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003eval_generator,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    callbacks\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e[early_stopping, model_checkpoint, tensorboard_callback]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch4 id=\"model-evaluation\"\u003eModel Evaluation\u003c/h4\u003e\n\u003ch2 id=\"test-accuracy\"\u003eTest Accuracy\u003c/h2\u003e\n\u003cp\u003eAfter training, we evaluate the model on the test set.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003etest_loss, test_acc \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e model\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eevaluate(test_generator)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eprint(\u003cspan style=\"color:#e6db74\"\u003ef\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\\n\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003eTest accuracy: \u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e{\u003c/span\u003etest_acc\u003cspan style=\"color:#e6db74\"\u003e:\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e.2%\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e}\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eprint(\u003cspan style=\"color:#e6db74\"\u003ef\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Test loss: \u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e{\u003c/span\u003etest_loss\u003cspan style=\"color:#e6db74\"\u003e:\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e.4f\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e}\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"confusion-matrix\"\u003eConfusion Matrix\u003c/h2\u003e\n\u003cp\u003eWe plot the confusion matrix to visualize the model\u0026rsquo;s performance.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eplot_confusion_matrix\u003c/span\u003e():\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    test_generator\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ereset()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    predictions \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e model\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epredict(test_generator)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    predicted_classes \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e np\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eargmax(predictions, axis\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    cm \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e confusion_matrix(test_generator\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eclasses, predicted_classes)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efigure(figsize\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e(\u003cspan style=\"color:#ae81ff\"\u003e10\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e8\u003c/span\u003e))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    sns\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eheatmap(cm, annot\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e, fmt\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;d\u0026#39;\u003c/span\u003e, cmap\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Blues\u0026#39;\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                xticklabels\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003eclass_names,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                yticklabels\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003eclass_names)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003exlabel(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Predicted\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eylabel(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;True\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etitle(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Confusion Matrix\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eshow()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eplot_confusion_matrix()\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"visualizing-results\"\u003eVisualizing Results\u003c/h2\u003e\n\u003ch2 id=\"training-history\"\u003eTraining History\u003c/h2\u003e\n\u003cp\u003eWe plot the training and validation accuracy and loss to understand the model\u0026rsquo;s learning process.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003edef\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eplot_history\u003c/span\u003e(history):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    acc \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e history\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ehistory[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;accuracy\u0026#39;\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    val_acc \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e history\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ehistory[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;val_accuracy\u0026#39;\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    loss \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e history\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ehistory[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;loss\u0026#39;\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    val_loss \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e history\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ehistory[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;val_loss\u0026#39;\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    epochs_range \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e range(len(acc))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efigure(figsize\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e(\u003cspan style=\"color:#ae81ff\"\u003e12\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e5\u003c/span\u003e))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003esubplot(\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eplot(epochs_range, acc, label\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Training Accuracy\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eplot(epochs_range, val_acc, label\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Validation Accuracy\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elegend(loc\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;lower right\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etitle(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Training and Validation Accuracy\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003esubplot(\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eplot(epochs_range, loss, label\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Training Loss\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eplot(epochs_range, val_loss, label\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Validation Loss\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elegend(loc\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;upper right\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etitle(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Training and Validation Loss\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etight_layout()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eshow()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eplot_history(history)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"training-accuracy--loss-graph\"\u003eTraining Accuracy \u0026amp; Loss Graph\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/graph1.png\" alt=\"Accuracy and Loss\"\u003e\u003c/p\u003e\n\u003ch3 id=\"confusion-matrix-1\"\u003eConfusion Matrix\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/graph2.png\" alt=\"Confusion Matrix\"\u003e\u003c/p\u003e\n\u003ch3 id=\"conclusion\"\u003eConclusion\u003c/h3\u003e\n\u003cp\u003eIn this project, we successfully built a deep learning model to classify different types of plastic using \u003cstrong\u003eTransfer Learning\u003c/strong\u003e with \u003cstrong\u003eMobileNetV2\u003c/strong\u003e. The model achieved a test accuracy of \u003cstrong\u003e75.94%\u003c/strong\u003e, which is a good starting point for further improvements.\u003c/p\u003e\n\u003ch3 id=\"future-work\"\u003eFuture Work\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eData Augmentation\u003c/strong\u003e: Experiment with more advanced augmentation techniques.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eModel Tuning\u003c/strong\u003e: Fine-tune the hyperparameters for better performance.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLarger Dataset\u003c/strong\u003e: Collect more data to improve the model\u0026rsquo;s accuracy.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"references\"\u003eReferences\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.tensorflow.org/\"\u003eTensorFlow Documentation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://arxiv.org/abs/1801.04381\"\u003eMobileNetV2 Paper\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis blog post provides a step-by-step guide to building a plastic classification model using Transfer Learning. The code and explanations are designed to be easy to follow, even for beginners. Feel free to explore the \u003ca href=\"https://github.com/yourusername/plastic-classification\"\u003eGitHub repository\u003c/a\u003e for the complete code and dataset.\u003c/p\u003e\n","description":"A deep learning model to classify different types of plastic using TensorFlow with GPU acceleration.","image":"/images/plastic_blog.png","permalink":"https://likhith1409.github.io/likhith_portfolio/blogs/plastic-classification-with-tensorflow/","title":"Plastic Classification using Transfer Learning"},{"content":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eThe \u003cstrong\u003eAI-API Integrator\u003c/strong\u003e project is a powerful solution aimed at integrating AI models with various applications seamlessly. With this tool, developers can easily integrate pre-trained AI models into their systems using APIs. The project is based on Python and Flask, ensuring a lightweight yet robust framework for your AI needs.\u003c/p\u003e\n\u003ch2 id=\"features\"\u003eFeatures\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eSimple Integration\u003c/strong\u003e: Connect any AI model via an easy-to-use API.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eScalable\u003c/strong\u003e: Built for large-scale applications, with support for multiple models and API endpoints.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLightweight\u003c/strong\u003e: Developed with Python and Flask for fast execution and minimal overhead.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eTo install the AI-API Integrator, simply clone the repository and install the dependencies:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit clone https://github.com/likhith1409/AI-API-Integrator.git\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ecd AI-API-Integrator\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epip install Flask\u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e2.2.2 cohere\u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e4.2.0 google-generativeai\u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e0.1.0 scikit-learn\u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e1.0.2 groq\u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e0.3.1\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"usage\"\u003eUsage\u003c/h2\u003e\n\u003cp\u003eAfter installing, run the Flask app:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epython app.py\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThis will start the API server, ready for integrating your AI models.\u003c/p\u003e\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eThe AI-API Integrator is a powerful tool for developers looking to integrate AI models quickly and efficiently. Whether you\u0026rsquo;re building a personal project or scaling for enterprise applications, this tool provides an excellent starting point. Check out the full repository on GitHub.\u003c/p\u003e\n","description":"An easy-to-use API integration tool designed for AI projects","image":"/images/API_Integrator.png","permalink":"https://likhith1409.github.io/likhith_portfolio/blogs/ai_api_integrator/","title":"AI-API-Integrator"},{"content":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eXGBoostGuard\u003c/strong\u003e is a robust fraud detection system built with the powerful XGBoost machine learning algorithm. It leverages various transaction-related features to detect potential fraudulent transactions automatically. With an impressive 99.00% accuracy rate, XGBoostGuard is designed to protect online payments from fraud and is an essential tool for financial institutions and e-commerce platforms.\u003c/p\u003e\n\u003ch2 id=\"features\"\u003eFeatures\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eHigh Accuracy\u003c/strong\u003e: Achieves a 99.00% accuracy rate in detecting fraudulent transactions.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEfficient Model\u003c/strong\u003e: Built using the XGBoost algorithm for fast and scalable fraud detection.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReal-Time Predictions\u003c/strong\u003e: Designed for quick decision-making, enabling real-time fraud detection.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eUser Input Integration\u003c/strong\u003e: Allows users to input transaction details and predict fraud status instantly.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eTo get started with XGBoostGuard, clone the repository and install the required dependencies:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit clone https://github.com/likhith1409/XGBoostGuard_Detecting_Online_Payment_Fraud_with_XGBoost.git\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ecd XGBoostGuard\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epip install xgboost pandas matplotlib scikit-learn\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"steps-ive-followed\"\u003eSteps I\u0026rsquo;ve Followed\u003c/h2\u003e\n\u003ch3 id=\"data-preparation\"\u003eData Preparation\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eLibraries and Packages\u003c/strong\u003e: I began by importing the necessary libraries and installing the required packages.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eData Loading\u003c/strong\u003e: I loaded the dataset from a CSV file named \u003ca href=\"https://drive.google.com/file/d/1O90u1b67QqpEEcQT-iEOs0J72zmo06w6/view?usp=sharing\"\u003eonlinefraud.csv\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eData Exploration\u003c/strong\u003e:\n\u003cul\u003e\n\u003cli\u003eChecked the dataset\u0026rsquo;s shape to understand its size.\u003c/li\u003e\n\u003cli\u003eDisplayed the first few rows to get an initial look at the data.\u003c/li\u003e\n\u003cli\u003eDealt with missing data by removing rows with missing values.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eData Visualization\u003c/strong\u003e: Visualized feature relationships using a correlation matrix heatmap to see how different features correlate.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"feature-selection-and-data-splitting\"\u003eFeature Selection and Data Splitting\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eData Splitting\u003c/strong\u003e:\n\u003cul\u003e\n\u003cli\u003eDivided the data into two parts: input features (X) and the target variable (y).\u003c/li\u003e\n\u003cli\u003eSplit the data into training and testing sets for model training and evaluation.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFeature Engineering\u003c/strong\u003e:\n\u003cul\u003e\n\u003cli\u003eExcluded non-numeric columns (\u0026rsquo;nameOrig\u0026rsquo;, \u0026rsquo;nameDest\u0026rsquo;, \u0026rsquo;type\u0026rsquo;) from the data since XGBoost requires numeric input.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"model-building\"\u003eModel Building\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eCreated an XGBoost classifier model, known for its effectiveness in handling complex data.\u003c/li\u003e\n\u003cli\u003eTrained the model using the training data, allowing it to learn patterns in the data.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"model-evaluation\"\u003eModel Evaluation\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eTo assess the model\u0026rsquo;s performance, I used various evaluation techniques:\n\u003cul\u003e\n\u003cli\u003eMade predictions on the test set and calculated the accuracy of the model.\u003c/li\u003e\n\u003cli\u003eGenerated a classification report that included metrics like precision, recall, and F1-score.\u003c/li\u003e\n\u003cli\u003eUtilized the confusion matrix and the Receiver Operating Characteristic (ROC) curve to visualize the model\u0026rsquo;s performance in distinguishing between fraudulent and non-fraudulent transactions.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"user-input-and-prediction\"\u003eUser Input and Prediction\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eAdded a user interaction feature where a user can input data for a new transaction.\u003c/li\u003e\n\u003cli\u003eUsed the trained model to predict whether the user\u0026rsquo;s input is a fraudulent transaction or not.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"precision-recall-curve\"\u003ePrecision-Recall Curve\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eIncluded a Precision-Recall curve to evaluate the precision and recall trade-off of the model.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"graphs-and-visualizations\"\u003eGraphs and Visualizations\u003c/h2\u003e\n\u003cp\u003eThe following visualizations provide valuable insights into the model\u0026rsquo;s performance:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eCorrelation Matrix Heatmap\u003c/strong\u003e: Helps understand how features are related to each other.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eConfusion Matrix\u003c/strong\u003e: Provides insights into the model\u0026rsquo;s classification performance.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eROC Curve and AUC\u003c/strong\u003e: Give a holistic view of how well the model separates fraudulent and non-fraudulent transactions.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePrecision-Recall Curve\u003c/strong\u003e: Assesses precision and recall, essential in detecting rare fraud cases.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"https://github.com/likhith1409/XGBoostGuard_Detecting_Online_Payment_Fraud_with_XGBoost/assets/91020626/b401df13-3098-483d-8c7c-ddb563498069\" alt=\"xgboost1\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://github.com/likhith1409/XGBoostGuard_Detecting_Online_Payment_Fraud_with_XGBoost/assets/91020626/51dfe959-9215-41ea-a007-698f6a976ea7\" alt=\"xgboost2\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://github.com/likhith1409/XGBoostGuard_Detecting_Online_Payment_Fraud_with_XGBoost/assets/91020626/87033fd3-33ec-4687-8534-c7a2fd9b873b\" alt=\"xgboost3\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://github.com/likhith1409/XGBoostGuard_Detecting_Online_Payment_Fraud_with_XGBoost/assets/91020626/2fae760a-4a3f-4c9b-9021-1586f1642ecc\" alt=\"xgboost4\"\u003e\u003c/p\u003e\n\u003ch3 id=\"accuracy\"\u003eAccuracy\u003c/h3\u003e\n\u003cp\u003eI used accuracy as a primary metric to determine the model\u0026rsquo;s overall correctness in classifying transactions. However, I\u0026rsquo;m aware that accuracy alone might not be enough, especially for imbalanced datasets. For this model, accuracy is 99.00%.\u003c/p\u003e\n\u003ch2 id=\"future-improvements\"\u003eFuture Improvements\u003c/h2\u003e\n\u003cp\u003eTo make my project even better, I\u0026rsquo;m considering the following:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eHyperparameter Fine-Tuning\u003c/strong\u003e: Fine-tuning the model\u0026rsquo;s hyperparameters for better performance.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFeature Engineering\u003c/strong\u003e: Exploring feature engineering to potentially create new features that can improve fraud detection.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAnomaly Detection\u003c/strong\u003e: Implementing anomaly detection techniques alongside classification to enhance detection of unusual fraud patterns.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReal-Time Integration\u003c/strong\u003e: Integrating the model into a real-time transaction processing system for immediate fraud detection.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eModel Interpretability\u003c/strong\u003e: Ensuring model interpretability, so I can understand and explain why the model makes specific predictions.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eData Augmentation\u003c/strong\u003e: Exploring data augmentation techniques to balance the dataset by generating synthetic data for the minority class (fraud). By addressing these aspects, I aim to improve the robustness and effectiveness of my fraud detection model, making it more accurate and reliable in identifying fraudulent transactions.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"conclusion\"\u003eConclusion\u003c/h3\u003e\n\u003cp\u003eXGBoostGuard is an effective tool for detecting online payment fraud, achieving high accuracy and performance in classifying fraudulent transactions. It is suitable for integrating into financial systems to safeguard transactions. The future improvements will make the system even more robust, with real-time integration and enhanced model interpretability.\u003c/p\u003e\n\u003cp\u003eCheck out the full project on \u003ca href=\"https://github.com/likhith1409/XGBoostGuard_Detecting_Online_Payment_Fraud_with_XGBoost\"\u003eGitHub\u003c/a\u003e and the live demo on \u003ca href=\"https://xgboostguard.streamlit.app/\"\u003eStreamlit\u003c/a\u003e.\u003c/p\u003e\n","description":"A fraud detection system using XGBoost to detect online payment fraud with high accuracy","image":"/images/xgboost.png","permalink":"https://likhith1409.github.io/likhith_portfolio/blogs/xgboostguard-detecting-online-payment-fraud/","title":"XGBoostGuard - Detecting Online Payment Fraud with XGBoost"}]